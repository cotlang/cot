@safe

// Map(K, V) — Production-quality generic hash map.
//
// Design: Open addressing with linear probing, power-of-2 capacity, 75% load factor.
// Deletion uses tombstones for probe chain correctness.
//
// References:
//   Zig:  std/hash_map.zig (open addressing, probing, rehash)
//   Go:   runtime/maps/ (growth, tombstones)
//   Hash: splitmix64 mixer (Sebastiano Vigna, xorshift.di.unimi.it/splitmix64.c)
//
// Known limitations (acceptable for V1, same tradeoffs as Zig):
//   - States use i64 per slot (8 bytes vs Zig's 1 byte). Optimize to u8 when available.
//   - No fingerprinting (Zig stores 7-bit hash fingerprint per slot for faster probing).
//   - Three separate allocations (keys, values, states) vs Zig's single allocation.
//   - Tombstone accumulation under heavy delete workloads degrades probe performance.
//     Long-lived maps with churn should periodically free() and rebuild.

import "std/list"
import "std/sys"

trait Hashable {
    fn hash(self: *Self) i64
}

// splitmix64 mixer: two rounds of xor-shift-multiply, final xor-shift.
// Constants from Sebastiano Vigna's splitmix64.c:
//   0xbf58476d1ce4e5b9 = -4658895280553007687 (signed i64)
//   0x94d049bb133111eb = -7723592293110705685 (signed i64)
// Shifts: 30, 27, 31 (standard splitmix64 values for 64-bit mixing).
// Cot's >> compiles to wasm i64.shr_u (logical shift), same as C's >> on uint64_t.
impl Hashable for i64 {
    fn hash(self: *i64) i64 {
        var h: i64 = self.*
        h = (h ^ (h >> 30)) * (0 - 4658895280553007687)
        h = (h ^ (h >> 27)) * (0 - 7723592293110705685)
        h = h ^ (h >> 31)
        return h
    }
}

// FNV-1a 64-bit hash for strings.
// Ref: Zig std.hash.Fnv1a_64, Go hash/fnv, Rust core::hash::SipHash
// Constants: offset_basis = 14695981039346656037 = -(3750763034362895579) signed
//            prime = 1099511628211
impl Hashable for string {
    fn hash(self: *string) i64 {
        var s = self.*
        var ptr = @ptrOf(s)
        var slen = @lenOf(s)
        var h: i64 = 0 - 3750763034362895579
        var i: i64 = 0
        while (i < slen) {
            var b = @intToPtr(*i64, ptr + i).* & 255
            h = (h ^ b) * 1099511628211
            i += 1
        }
        return h
    }
}

struct Map(K, V) {
    keys: i64,
    values: i64,
    states: i64,
    count: i64,
    capacity: i64,
}

impl Map(K, V) {
    // ===== Internal =====

    fn ensureCapacity(self: Map(K, V), needed: i64) void {
        // Check if we need to grow: count * 4 >= capacity * 3 (75% load factor)
        if (self.capacity > 0) {
            if (needed * 4 < self.capacity * 3) {
                return
            }
        }
        var new_cap = self.capacity
        if (new_cap == 0) { new_cap = 8 }
        while (needed * 4 >= new_cap * 3) {
            new_cap *= 2
        }
        self.rehash(new_cap)
    }

    fn rehash(self: Map(K, V), new_cap: i64) void {
        var old_keys = self.keys
        var old_values = self.values
        var old_states = self.states
        var old_capacity = self.capacity

        // Allocate new arrays
        self.keys = alloc(0,new_cap * @sizeOf(K))
        self.values = alloc(0,new_cap * @sizeOf(V))
        self.states = alloc(0,new_cap * @sizeOf(i64))
        self.capacity = new_cap
        self.count = 0

        // Initialize all states to 0 (empty)
        var si: i64 = 0
        while (si < new_cap) {
            var sp = @intToPtr(*i64, self.states + si * @sizeOf(i64))
            sp.* = 0
            si += 1
        }

        // Reinsert all occupied entries from old table.
        // Fresh table has no tombstones, so only check for empty (state=0).
        var oi: i64 = 0
        while (oi < old_capacity) {
            var os = @intToPtr(*i64, old_states + oi * @sizeOf(i64))
            if (os.* == 1) {
                var ok = @intToPtr(*K, old_keys + oi * @sizeOf(K))
                var ov = @intToPtr(*V, old_values + oi * @sizeOf(V))
                self.set(ok.*, ov.*)
            }
            oi += 1
        }

        // Free old arrays
        if (old_capacity > 0) {
            dealloc(old_keys)
            dealloc(old_values)
            dealloc(old_states)
        }
    }

    // ===== Capacity =====

    // Ref: Zig HashMap.ensureTotalCapacity() — pre-allocate for known sizes.
    // Given n entries, allocates enough capacity to hold n entries without rehashing.
    fn ensureTotalCapacity(self: Map(K, V), n: i64) void {
        if (n <= 0) { return }
        self.ensureCapacity(n)
    }

    // ===== Core =====

    fn set(self: Map(K, V), key: K, value: V) void {
        // Ensure we have capacity (75% load factor)
        if (self.capacity == 0) {
            self.rehash(8)
        } else {
            if ((self.count + 1) * 4 >= self.capacity * 3) {
                self.rehash(self.capacity * 2)
            }
        }

        var k = key
        var h = k.hash()
        var idx = h & (self.capacity - 1)
        var first_tombstone: i64 = 0 - 1

        var i: i64 = 0
        while (i < self.capacity) {
            var st = @intToPtr(*i64, self.states + idx * @sizeOf(i64))
            if (st.* == 0) {
                // Empty slot — use tombstone slot if we found one, else this slot
                var target = idx
                if (first_tombstone >= 0) { target = first_tombstone }
                var kp = @intToPtr(*K, self.keys + target * @sizeOf(K))
                var vp = @intToPtr(*V, self.values + target * @sizeOf(V))
                var tp = @intToPtr(*i64, self.states + target * @sizeOf(i64))
                kp.* = key
                vp.* = value
                tp.* = 1
                self.count += 1
                return
            }
            if (st.* == 1) {
                var kp = @intToPtr(*K, self.keys + idx * @sizeOf(K))
                if (kp.* == key) {
                    // Key exists — release old value, store new
                    var vp = @intToPtr(*V, self.values + idx * @sizeOf(V))
                    @arcRelease(vp.*)
                    vp.* = value
                    return
                }
            }
            if (st.* == 2) {
                if (first_tombstone < 0) {
                    first_tombstone = idx
                }
            }
            idx = (idx + 1) & (self.capacity - 1)
            i += 1
        }
        // Unreachable: 75% load factor guarantees an empty slot exists.
        @trap()
    }

    fn get(self: Map(K, V), key: K) V {
        if (self.capacity == 0) { @trap() }
        var k = key
        var h = k.hash()
        var idx = h & (self.capacity - 1)

        var i: i64 = 0
        while (i < self.capacity) {
            var st = @intToPtr(*i64, self.states + idx * @sizeOf(i64))
            if (st.* == 0) { @trap() }
            if (st.* == 1) {
                var kp = @intToPtr(*K, self.keys + idx * @sizeOf(K))
                if (kp.* == key) {
                    var vp = @intToPtr(*V, self.values + idx * @sizeOf(V))
                    return vp.*
                }
            }
            idx = (idx + 1) & (self.capacity - 1)
            i += 1
        }
        @trap()
        return @intToPtr(*V, 0).*
    }

    // Ref: Zig HashMap.get() returns ?V — safe lookup, null on missing key.
    fn getOrNull(self: Map(K, V), key: K) ?V {
        if (self.capacity == 0) { return null }
        var k = key
        var h = k.hash()
        var idx = h & (self.capacity - 1)

        var i: i64 = 0
        while (i < self.capacity) {
            var st = @intToPtr(*i64, self.states + idx * @sizeOf(i64))
            if (st.* == 0) { return null }
            if (st.* == 1) {
                var kp = @intToPtr(*K, self.keys + idx * @sizeOf(K))
                if (kp.* == key) {
                    var vp = @intToPtr(*V, self.values + idx * @sizeOf(V))
                    return vp.*
                }
            }
            idx = (idx + 1) & (self.capacity - 1)
            i += 1
        }
        return null
    }

    fn getOrDefault(self: Map(K, V), key: K, default: V) V {
        if (self.capacity == 0) { return default }
        var k = key
        var h = k.hash()
        var idx = h & (self.capacity - 1)

        var i: i64 = 0
        while (i < self.capacity) {
            var st = @intToPtr(*i64, self.states + idx * @sizeOf(i64))
            if (st.* == 0) { return default }
            if (st.* == 1) {
                var kp = @intToPtr(*K, self.keys + idx * @sizeOf(K))
                if (kp.* == key) {
                    var vp = @intToPtr(*V, self.values + idx * @sizeOf(V))
                    return vp.*
                }
            }
            idx = (idx + 1) & (self.capacity - 1)
            i += 1
        }
        return default
    }

    fn has(self: Map(K, V), key: K) i64 {
        if (self.capacity == 0) { return 0 }
        var k = key
        var h = k.hash()
        var idx = h & (self.capacity - 1)

        var i: i64 = 0
        while (i < self.capacity) {
            var st = @intToPtr(*i64, self.states + idx * @sizeOf(i64))
            if (st.* == 0) { return 0 }
            if (st.* == 1) {
                var kp = @intToPtr(*K, self.keys + idx * @sizeOf(K))
                if (kp.* == key) { return 1 }
            }
            idx = (idx + 1) & (self.capacity - 1)
            i += 1
        }
        return 0
    }

    // Ref: Zig HashMap.contains() returns bool — idiomatic membership test.
    fn contains(self: Map(K, V), key: K) bool {
        if (self.capacity == 0) { return false }
        var k = key
        var h = k.hash()
        var idx = h & (self.capacity - 1)

        var i: i64 = 0
        while (i < self.capacity) {
            var st = @intToPtr(*i64, self.states + idx * @sizeOf(i64))
            if (st.* == 0) { return false }
            if (st.* == 1) {
                var kp = @intToPtr(*K, self.keys + idx * @sizeOf(K))
                if (kp.* == key) { return true }
            }
            idx = (idx + 1) & (self.capacity - 1)
            i += 1
        }
        return false
    }

    // Ref: Zig HashMap rehashes to clean tombstones when load factor is unhealthy
    fn delete(self: Map(K, V), key: K) void {
        if (self.capacity == 0) { return }
        var k = key
        var h = k.hash()
        var idx = h & (self.capacity - 1)

        var i: i64 = 0
        while (i < self.capacity) {
            var st = @intToPtr(*i64, self.states + idx * @sizeOf(i64))
            if (st.* == 0) { return }
            if (st.* == 1) {
                var kp = @intToPtr(*K, self.keys + idx * @sizeOf(K))
                if (kp.* == key) {
                    @arcRelease(kp.*)
                    var dvp = @intToPtr(*V, self.values + idx * @sizeOf(V))
                    @arcRelease(dvp.*)
                    st.* = 2
                    self.count -= 1
                    // Tombstone cleanup: if tombstones > capacity/4, rehash at same capacity
                    // Count tombstones by scanning states
                    var tombstones: i64 = 0
                    var ti: i64 = 0
                    while (ti < self.capacity) {
                        var ts = @intToPtr(*i64, self.states + ti * @sizeOf(i64))
                        if (ts.* == 2) { tombstones += 1 }
                        ti += 1
                    }
                    if (tombstones > self.capacity / 4) {
                        self.rehash(self.capacity)
                    }
                    return
                }
            }
            idx = (idx + 1) & (self.capacity - 1)
            i += 1
        }
    }

    // Ref: Zig HashMap.fetchRemove() returns ?Entry — remove key, return old value.
    // Distinct from delete() which returns void.
    fn remove(self: Map(K, V), key: K) ?V {
        if (self.capacity == 0) { return null }
        var k = key
        var h = k.hash()
        var idx = h & (self.capacity - 1)

        var i: i64 = 0
        while (i < self.capacity) {
            var st = @intToPtr(*i64, self.states + idx * @sizeOf(i64))
            if (st.* == 0) { return null }
            if (st.* == 1) {
                var kp = @intToPtr(*K, self.keys + idx * @sizeOf(K))
                if (kp.* == key) {
                    var vp = @intToPtr(*V, self.values + idx * @sizeOf(V))
                    var value = vp.*
                    @arcRelease(kp.*)
                    st.* = 2
                    self.count -= 1
                    return value
                }
            }
            idx = (idx + 1) & (self.capacity - 1)
            i += 1
        }
        return null
    }

    // ===== Info =====

    fn len(self: Map(K, V)) i64 { return self.count }

    fn isEmpty(self: Map(K, V)) i64 {
        if (self.count == 0) { return 1 }
        return 0
    }

    // ===== Lifecycle =====

    fn free(self: Map(K, V)) void {
        // Release all ARC-managed keys and values before deallocating.
        var fi: i64 = 0
        while (fi < self.capacity) {
            var fst = @intToPtr(*i64, self.states + fi * @sizeOf(i64))
            if (fst.* == 1) {
                var fkp = @intToPtr(*K, self.keys + fi * @sizeOf(K))
                var fvp = @intToPtr(*V, self.values + fi * @sizeOf(V))
                @arcRelease(fkp.*)
                @arcRelease(fvp.*)
            }
            fi += 1
        }
        if (self.capacity > 0) {
            dealloc(self.keys)
            dealloc(self.values)
            dealloc(self.states)
        }
        self.keys = 0
        self.values = 0
        self.states = 0
        self.count = 0
        self.capacity = 0
    }

    fn clear(self: Map(K, V)) void {
        // Release all ARC-managed keys and values before clearing.
        var ci: i64 = 0
        while (ci < self.capacity) {
            var cst = @intToPtr(*i64, self.states + ci * @sizeOf(i64))
            if (cst.* == 1) {
                var ckp = @intToPtr(*K, self.keys + ci * @sizeOf(K))
                var cvp = @intToPtr(*V, self.values + ci * @sizeOf(V))
                @arcRelease(ckp.*)
                @arcRelease(cvp.*)
            }
            cst.* = 0
            ci += 1
        }
        self.count = 0
    }

    fn clearAndFree(self: Map(K, V)) void {
        self.free()
    }

    // ===== Bulk =====

    fn keys(self: Map(K, V)) List(K) {
        var result: List(K) = .{}
        var i: i64 = 0
        while (i < self.capacity) {
            var st = @intToPtr(*i64, self.states + i * @sizeOf(i64))
            if (st.* == 1) {
                var kp = @intToPtr(*K, self.keys + i * @sizeOf(K))
                result.append(kp.*)
            }
            i += 1
        }
        return result
    }

    fn values(self: Map(K, V)) List(V) {
        var result: List(V) = .{}
        var i: i64 = 0
        while (i < self.capacity) {
            var st = @intToPtr(*i64, self.states + i * @sizeOf(i64))
            if (st.* == 1) {
                var vp = @intToPtr(*V, self.values + i * @sizeOf(V))
                result.append(vp.*)
            }
            i += 1
        }
        return result
    }

    // entries() — returns parallel key and value Lists for iteration.
    // Usage: var ek = m.entryKeys(); var ev = m.entryValues(); then index both.
    // More efficient: use keys() + get() pattern, or keyAt/valueAt indexed access.
    // Reference: Zig HashMap.iterator() yields Entry{.key, .value}

    // keyAt(n) — returns the nth occupied key (0-indexed among live entries).
    // Reference: Zig HashMap iterator pattern — skip empty/tombstone slots.
    fn keyAt(self: Map(K, V), n: i64) K {
        var count: i64 = 0
        var i: i64 = 0
        while (i < self.capacity) {
            var st = @intToPtr(*i64, self.states + i * @sizeOf(i64))
            if (st.* == 1) {
                if (count == n) {
                    var kp = @intToPtr(*K, self.keys + i * @sizeOf(K))
                    return kp.*
                }
                count += 1
            }
            i += 1
        }
        @trap()
        return @intToPtr(*K, 0).*
    }

    // valueAt(n) — returns the nth occupied value (0-indexed among live entries).
    fn valueAt(self: Map(K, V), n: i64) V {
        var count: i64 = 0
        var i: i64 = 0
        while (i < self.capacity) {
            var st = @intToPtr(*i64, self.states + i * @sizeOf(i64))
            if (st.* == 1) {
                if (count == n) {
                    var vp = @intToPtr(*V, self.values + i * @sizeOf(V))
                    return vp.*
                }
                count += 1
            }
            i += 1
        }
        @trap()
        return @intToPtr(*V, 0).*
    }

    // clone() — deep copy of the map. All entries re-inserted.
    // Reference: Zig HashMap.clone(), Go maps.Clone()
    fn clone(self: Map(K, V)) Map(K, V) {
        var result: Map(K, V) = .{}
        if (self.count == 0) { return result }
        result.rehash(self.capacity)
        var i: i64 = 0
        while (i < self.capacity) {
            var st = @intToPtr(*i64, self.states + i * @sizeOf(i64))
            if (st.* == 1) {
                var kp = @intToPtr(*K, self.keys + i * @sizeOf(K))
                var vp = @intToPtr(*V, self.values + i * @sizeOf(V))
                result.set(kp.*, vp.*)
            }
            i += 1
        }
        return result
    }

    // putAll(other) — merge all entries from other into self. Overwrites on key conflict.
    // Reference: Zig HashMap.putAll(), Java HashMap.putAll()
    fn putAll(self: Map(K, V), other: *Map(K, V)) void {
        var i: i64 = 0
        while (i < other.capacity) {
            var st = @intToPtr(*i64, other.states + i * @sizeOf(i64))
            if (st.* == 1) {
                var kp = @intToPtr(*K, other.keys + i * @sizeOf(K))
                var vp = @intToPtr(*V, other.values + i * @sizeOf(V))
                self.set(kp.*, vp.*)
            }
            i += 1
        }
    }
}
